{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "d61a9780",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Qdrant\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.llms.base import LLM\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from PyPDF2 import PdfReader  # Import PyPDF2 library\n",
    "from langchain.schema import Document\n",
    "from langchain_community.llms import GPT4All as gpt\n",
    "from gpt4all import GPT4All\n",
    "from pydantic import PrivateAttr\n",
    "\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "cec58856",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = 'C:/Users/utkut/Desktop/dataset/ragdata/portfolio.pdf'\n",
    "json_path = 'C:/Users/utkut/Desktop/dataset/company_metadata.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "715d5c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text_lower = text.lower()\n",
    "    text_no_punctuation = re.sub(r'[^\\w\\s\\$\\%\\.\\,\\\"\\'\\!\\?\\(\\)]', '', text_lower)\n",
    "    text_normalized_tabs = re.sub(r'(\\t)+', '', text_no_punctuation)\n",
    "    return text_lower\n",
    "\n",
    "# Process PDF documents\n",
    "reader = PdfReader(pdf_path)\n",
    "documents = []\n",
    "\n",
    "# Extract text content from each page\n",
    "for page in reader.pages:\n",
    "    documents.append(preprocess_text(page.extract_text()))\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0, separator=\"\\n\")\n",
    "pdf_docs = text_splitter.create_documents(documents)\n",
    "\n",
    "# Process JSON data\n",
    "with open(json_path, 'r', encoding='latin-1') as f:\n",
    "    json_data = json.load(f)\n",
    "\n",
    "json_documents = []\n",
    "for entry in json_data:\n",
    "    content = preprocess_text(json.dumps(entry))\n",
    "    json_documents.append({'page_content': content}) \n",
    "\n",
    "# Combine processed data\n",
    "all_docs = pdf_docs #+ [Document(page_content=doc['page_content']) for doc in json_documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "9e17e2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\utkut\\anaconda3\\envs\\finy\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Embeddings and Qdrant setup\n",
    "'''tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/distiluse-base-multilingual-cased-v2\", force_download=True, resume_download=False)\n",
    "model = AutoModel.from_pretrained(\"sentence-transformers/distiluse-base-multilingual-cased-v2\", force_download=True, resume_download=False)'''\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/distiluse-base-multilingual-cased-v2\", model_kwargs={'device': \"cpu\"})\n",
    "qdrant = Qdrant.from_documents(\n",
    "    all_docs,\n",
    "    embeddings,\n",
    "    location=\":memory:\",\n",
    "    collection_name=\"financial_data\",\n",
    "    force_recreate=True\n",
    ")\n",
    "\n",
    "#location=\":memory:\","
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "f9853e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Document(page_content='kritik unsuru çeşitli risk / getiri potansiyeline sahip alternatif portföyler \\narasından  optimal  portföyün belirlenmesi oluşturmaktadır. bu amaçla da hem \\nliteratürde hem de uygulamada port föy optimizasyon yöntemlerinden \\nyararlanılmaktadır.  \\nliteratürde öneminden dolayı oldukça farklı portföy optimizasyon \\nyöntemleri nin kullanıldığı görülmektedir. bu yöntemlere örnek olarak genetik \\nalgoritmaya dayalı portföy optimizasyon yöntemi, parçacık sürü  optimizasyon \\nyöntemi, çok amaçlı genetik algoritma yöntemi,  makine öğrenmesi ve derin \\nöğrenme algoritmaları,  hedef programlama yöntemi, bulanık ortalama mutlak \\nsapma yöntemi, black -litterman yöntemi, yapay sinir ağı yöntemi ve stokastik  \\nprogramlamaya daya lı yöntemler verilebilir (örneğin bakınız:  çelengi, eğrioğlu \\nve çorba, 2015 ; fernandez ve gomez , 2007 ; gökmen, 2009 ; klega, 2013 ; ma, \\nhan ve wang, 2021 ; özdemir, 2011 ; solatikia, kiliç ve weber, 2014 ; yakut ve \\nçankal, 2016 )', metadata={'_id': '707c754994db42409ce6cc9f04fe0180', '_collection_name': 'financial_data'}), 0.44230278347856)\n"
     ]
    }
   ],
   "source": [
    "query = \"Portföy optimizasyonu nedir?\"\n",
    "found_docs = qdrant.similarity_search_with_score(query,k=3)\n",
    "print(found_docs[0]) # print the first element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "a122922d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(query):\n",
    "    found_docs = qdrant.similarity_search_with_score(query,k=1)\n",
    "    return \"\\n\\n\".join(doc[0].page_content for doc in found_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "1c387c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Define the Runnable interface\n",
    "class Runnable:\n",
    "    def run(self, input):\n",
    "        raise NotImplementedError(\"Subclasses must implement this method\")\n",
    "\n",
    "# Step 2: Implement Runnable in GPT4All\n",
    "class GPT4All(Runnable):\n",
    "    \n",
    "    def __init__(self,model_name,n_threads,allow_download):\n",
    "        self.model_name = model_name\n",
    "        self.n_threads = n_threads\n",
    "        self.allow_download = allow_download\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "class StreamingStdOutCallbackHandler:\n",
    "    def __init__(self, callbacks=None):  # Fixed typo here\n",
    "        self.callbacks = callbacks if callbacks is not None else []\n",
    "        \n",
    "    def add_callback(self, callback):\n",
    "        self.callbacks.append(callback)\n",
    "        \n",
    "# Step 3 & 4: Modify LLMChain to use Runnable instances\n",
    "class LLMChain:\n",
    "    def __init__(self, prompt, llm, verbose=False):\n",
    "        if not isinstance(llm, Runnable):\n",
    "            raise TypeError(\"llm must be an instance of Runnable\")\n",
    "        self.prompt = prompt\n",
    "        self.llm = llm\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def invoke(self, input):\n",
    "        # Use the run method of the llm (which is guaranteed to be a Runnable)\n",
    "        return self.llm.run(input)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "c5168808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model = GPT4All(model_name=\"mistral-7b-instruct-v0.1.Q4_0.gguf\", n_threads=4, allow_download=True)\\n#SADECE MODELİ İNDİRİYOR'"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''model = GPT4All(model_name=\"mistral-7b-instruct-v0.1.Q4_0.gguf\", n_threads=4, allow_download=True)\n",
    "#SADECE MODELİ İNDİRİYOR'''\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "2017f306",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = gpt(\n",
    "            model=\"mistral-7b-instruct-v0.1.Q4_0.gguf\",\n",
    "            max_tokens=300,\n",
    "            n_threads = 4,\n",
    "            temp=0.3,\n",
    "            top_p=0.2,\n",
    "            top_k=40,\n",
    "            n_batch=8,\n",
    "            seed=100,\n",
    "            allow_download=True,\n",
    "            verbose=True)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "303e7f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#template = '''[INST]: Sen kullanıcıların şirketler ve piyasalar hakkında bilgi alabildiği, portföylerini yorumlayabilen uzman bir finansal asistansın. Aşağıda soruların sorulacağı taslak mevcuttur, değerli görüşlerinizi bu taslağa göre belirtmen istenmektedir.[\\INST]\\n\n",
    "#Context: {context}.\\n\n",
    "#Question: {question}\\n\n",
    "#Answer: '''\n",
    "\n",
    "template = \"\"\"\n",
    "### [INST] \n",
    "Instruction: Sen kullanıcıların şirketler ve piyasalar hakkında bilgi alabildiği, portföylerini yorumlayabilen uzman \n",
    "bir finansal asistansın. Aşağıda soruların sorulacağı taslak mevcuttur, değerli görüşlerinizi bu taslağa göre belirtmen istenmektedir:\n",
    "\n",
    "{context}\n",
    "\n",
    "### QUESTION:\n",
    "{question} \n",
    "\n",
    "[/INST]\n",
    " \"\"\"\n",
    "\n",
    "rag_prompt = PromptTemplate(template=template, input_variables=[\"context\", \"question\"])\n",
    "\n",
    "callbacks = [StreamingStdOutCallbackHandler()]\n",
    "\n",
    "#retriever = qdrant.as_retriever()\n",
    "\n",
    "llm_chain = LLMChain(prompt=rag_prompt, llm=llm, verbose = True)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "33b4f651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "### [INST] \n",
      "Instruction: Sen kullanıcıların şirketler ve piyasalar hakkında bilgi alabildiği, portföylerini yorumlayabilen uzman \n",
      "bir finansal asistansın. Aşağıda soruların sorulacağı taslak mevcuttur, değerli görüşlerinizi bu taslağa göre belirtmen istenmektedir:\n",
      "\n",
      "yeterli derinliği olan sermaye piyasaları ile daha uyumlu  olmasıdır2. çalışmada \n",
      "ayrıca literatürdeki temel portföy optimizasyon yöntemlerde n biri olması \n",
      "nedeniyle markowitz (1952) ortalama varyans yöntemine de yer verilmiştir.  \n",
      "çalışmanın literatüre çe şitli açılardan katkı sağladığı düşünülmektedir. \n",
      "öncelikle daha önce de ifade edildiği gibi ulusal yazında portföy optimizasyon \n",
      "konusunun oldukça ilgi  görmesine rağmen, o mega  rasyosu  ile cvar ve mdd \n",
      "yöntemlerinin henüz pek kullanılmadığı görülmektedir. i̇kinci olarak, bilindiği \n",
      "gibi, ilgili dört portfö y optimizasyon yönteminin ortak bir noktası \n",
      "bulunmaktadır. o da şudur ki ; ilgili dört portföy optimizasyon yönteminin de \n",
      "optimal portföyleri oluşturabilmesi için optimal portföyün hedeflenen yıllık \n",
      "getiri oranının yatırımcı tarafından önceden belirlenmesi gerekmektedir. bu \n",
      "nedenle bu çalışmada farklı yaklaşımlara karşı dirençli (robust) sonuçlar elde\n",
      "\n",
      "### QUESTION:\n",
      "Markowitz yöntemi nedir? \n",
      "\n",
      "[/INST]\n",
      " \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " Markowitz yöntemini, portföy optimizasyon için kullanılan bir matematiksel modelle tanımlayabilmektedir. Bu yöntem, sermaye piyasalarının varlığı ve riski ile ilişkili portföyler arasında daha uyumlu bir seçim yapmak için kullanılan bir algoritma olup, bu algoritmanın bulutu ortalaması (Markowitz Ortalama) adına verilmiştir. Bu yöntem, portföy optimizasyon konusunda ilgili dört portföy optimizasyon yöntemi arasında en uyumlu bir seçim yapmak için kullanılan bir algoritma olup, bu algoritmanın bulutu ortalaması (Markowitz Ortalama) adına verilmiştir. Bu yöntem,\n"
     ]
    }
   ],
   "source": [
    "query = \"Markowitz yöntemi nedir?\"\n",
    "resp = llm_chain.invoke(\n",
    "    input={\"question\":query,\n",
    "           \"context\": format_docs(query)\n",
    "          }\n",
    ")\n",
    "print(resp['text'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
